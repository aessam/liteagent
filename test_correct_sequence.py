#!/usr/bin/env python3
"""
Test the CORRECT sequencing: Parent establishes cache FIRST, then forks.
"""

import os
import sys
import time
from pathlib import Path

# Add the project root to the path
sys.path.insert(0, str(Path(__file__).parent))

from liteagent.forked_agent import ForkedAgent
from liteagent.provider_cost_tracker import get_cost_tracker

# Load environment variables
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass


def test_correct_sequence():
    """Test the correct sequencing to avoid rate limits."""
    print("ğŸ¯ TESTING CORRECT CACHE-FIRST SEQUENCE")
    print("="*60)
    
    # Reset cost tracker
    cost_tracker = get_cost_tracker()
    cost_tracker.events = []
    
    # Large content that definitely needs caching
    large_content = "This is large context for sequence testing. " * 1000  # ~45K chars
    print(f"ğŸ“Š Large content size: {len(large_content):,} characters")
    
    # Step 1: Create parent (no cache yet)
    print(f"\nğŸ¤– Step 1: Creating parent agent...")
    parent = ForkedAgent(
        model="claude-3-5-sonnet-20241022",
        name="sequence_parent",
        system_prompt=f"You are a comprehensive analysis system. CODEBASE: {large_content}",
        provider="anthropic",
        enable_caching=True,
        debug=True
    )
    print(f"âœ… Parent created: {parent.context_id}")
    print(f"ğŸ“‹ Parent has {len(parent.memory.get_messages())} messages")
    print(f"ğŸ” Cache prepared: {parent._is_prepared_for_caching()}")
    
    # Step 2: FORCE cache establishment BEFORE any forks
    print(f"\nğŸ”§ Step 2: Establishing cache (CRITICAL STEP)...")
    if not parent._is_prepared_for_caching():
        print("ğŸ’¡ Cache not prepared - establishing now...")
        parent._prepare_for_caching()
    else:
        print("âœ… Cache already prepared")
        
    print(f"ğŸ“‹ Parent now has {len(parent.memory.get_messages())} messages")
    print(f"ğŸ” Cache prepared: {parent._is_prepared_for_caching()}")
    
    # Check cost after cache establishment
    cache_cost = cost_tracker.get_total_cost()
    cache_tokens = cost_tracker.get_total_tokens()
    print(f"ğŸ’° Cache establishment cost: ${cache_cost:.6f} ({cache_tokens:,} tokens)")
    
    # Step 3: Create forks (should use existing cache)
    print(f"\nğŸ”€ Step 3: Creating forks (should inherit cache)...")
    
    fork1 = parent.fork(name="analyzer1", prefill_role="security expert")
    print(f"âœ… Fork 1 created with {len(fork1.memory.get_messages())} messages")
    
    fork2 = parent.fork(name="analyzer2", prefill_role="performance expert") 
    print(f"âœ… Fork 2 created with {len(fork2.memory.get_messages())} messages")
    
    # Step 4: Test fork conversations (should use cache)
    print(f"\nğŸ’¬ Step 4: Testing fork conversations...")
    
    print(f"   ğŸ” Testing fork 1...")
    try:
        response1 = fork1.chat("Provide a brief analysis.")
        print(f"      âœ… Success: {response1[:50]}...")
        
        # Check cost
        cost_after_1 = cost_tracker.get_total_cost()
        tokens_after_1 = cost_tracker.get_total_tokens()
        fork1_cost = cost_after_1 - cache_cost
        fork1_tokens = tokens_after_1 - cache_tokens
        print(f"      ğŸ’° Fork 1 cost: ${fork1_cost:.6f} ({fork1_tokens:,} tokens)")
        
    except Exception as e:
        print(f"      âŒ Failed: {e}")
        if "rate_limit" in str(e).lower():
            print(f"      ğŸš¨ RATE LIMIT! Cache sequence failed!")
            return
    
    # Small delay to be extra safe
    print(f"   â±ï¸ Brief pause before fork 2...")
    time.sleep(1)
    
    print(f"   âš¡ Testing fork 2...")
    try:
        response2 = fork2.chat("Provide a brief analysis.")
        print(f"      âœ… Success: {response2[:50]}...")
        
        # Final cost
        final_cost = cost_tracker.get_total_cost()
        final_tokens = cost_tracker.get_total_tokens()
        fork2_cost = final_cost - cost_after_1
        fork2_tokens = final_tokens - tokens_after_1
        print(f"      ğŸ’° Fork 2 cost: ${fork2_cost:.6f} ({fork2_tokens:,} tokens)")
        
    except Exception as e:
        print(f"      âŒ Failed: {e}")
        if "rate_limit" in str(e).lower():
            print(f"      ğŸš¨ RATE LIMIT! Even with correct sequence!")
    
    # Final analysis
    print(f"\nğŸ“Š SEQUENCE ANALYSIS:")
    total_cached = 0
    total_created = 0
    
    for event in cost_tracker.get_summary().get('events', []):
        cached = event.get('cache_read_input_tokens', 0) + event.get('cached_tokens', 0)
        created = event.get('cache_creation_input_tokens', 0)
        total_cached += cached
        total_created += created
        
        if cached > 0 or created > 0:
            agent = event.get('agent_name', 'unknown')
            print(f"   ğŸ¯ {agent}: created {created:,}, used {cached:,}")
    
    print(f"\n   ğŸ“ˆ Final Summary:")
    print(f"      â€¢ Cache created: {total_created:,} tokens")
    print(f"      â€¢ Cache reused: {total_cached:,} tokens") 
    print(f"      â€¢ Total cost: ${final_cost:.6f}")
    
    if total_cached > total_created:
        print(f"      âœ… SUCCESS: More cache reuse than creation!")
        print(f"      âœ… Correct sequence prevented rate limits!")
    else:
        print(f"      âš ï¸ Limited cache reuse - may need larger delays")
    
    print(f"\nğŸ¯ Test completed!")


if __name__ == "__main__":
    test_correct_sequence()