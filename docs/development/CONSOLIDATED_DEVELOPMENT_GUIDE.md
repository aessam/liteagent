# LiteAgent Development Guide
*High-density consolidated documentation - everything you need to know*

## üèóÔ∏è Architecture Overview

**Core Components:**
- `LiteAgent`: Main orchestrator (chat, tools, memory, observers)
- `ModelInterface`: Provider adapters (OpenAI, Anthropic, Groq, Ollama)
- `ToolCallingHandler`: Provider-specific extraction/formatting
- `ConversationMemory`: History + loop detection
- `AgentObserver`: Event system (console, file, trace)

**Tool System:**
- `@liteagent_tool`: Decorator for functions/methods
- `FunctionTool`: Standalone functions
- `InstanceMethodTool`: Class methods
- `AgentTool`: Agent-as-tool pattern

**Multi-Agent:**
```python
manager = LiteAgent(model="gpt-4o-mini")
coder = LiteAgent(model="claude-3-opus", parent_context_id=manager.context_id)
manager.tools = [coder.as_tool(name="code_writer")]
```

## üõ†Ô∏è Function Calling Architecture (2025)

**Provider Handlers:**
- `OpenAIToolCallingHandler` (112 lines): Native `tools` parameter, `parallel_tool_calls=true`
- `AnthropicToolCallingHandler` (122 lines): `input_schema` format, parallel support
- `GroqToolCallingHandler` (123 lines): OpenAI-compatible, 128 tool limit
- `OllamaToolCallingHandler` (137 lines): Native format, 10 tool limit
- `TextBasedToolCallingHandler`: Legacy models without native support
- `StructuredOutputHandler`: JSON extraction for legacy models

**Correct Formats:**
```python
# OpenAI/Groq
{"tools": [{"type": "function", "function": {"name": "...", "parameters": {...}}}]}

# Anthropic  
{"tools": [{"name": "...", "input_schema": {...}}]}

# Tool Results
{"role": "tool", "tool_call_id": "...", "content": "..."}  # OpenAI
{"type": "tool_result", "tool_use_id": "...", "content": "..."}  # Anthropic
```

**XPath Complexity Removed:**
- ‚ùå `xpath_extractor.py` (226 lines)
- ‚ùå `tool_calling_detection.py` (141 lines) 
- ‚ùå `pattern_tool_handler.py` (403 lines)
- ‚ùå `auto_detect_handler.py` (109 lines)
- ‚úÖ Direct provider-to-handler mapping (no runtime detection)

## üìÅ Repository Structure (Python Standards)

```
liteagent/
‚îú‚îÄ‚îÄ pyproject.toml              # Modern packaging only
‚îú‚îÄ‚îÄ README.md, LICENSE
‚îú‚îÄ‚îÄ liteagent/                  # Main package
‚îÇ   ‚îú‚îÄ‚îÄ __main__.py             # CLI entry
‚îÇ   ‚îú‚îÄ‚îÄ handlers/               # Provider handlers
‚îÇ   ‚îú‚îÄ‚îÄ models.py               # Core functionality  
‚îÇ   ‚îî‚îÄ‚îÄ simple_tool_handler.py  # Clean base class
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/                   # Isolated tests
‚îÇ   ‚îî‚îÄ‚îÄ integration/            # Cross-component tests
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ examples/               # Moved from root
‚îÇ   ‚îî‚îÄ‚îÄ development/            # This file
‚îî‚îÄ‚îÄ scripts/dev-tools/          # Moved from tools/
```

**Removed Files:**
- `liteagent.egg-info/`, `static/`, `pytestdebug.log`
- `setup.py`, `requirements.txt`, `MANIFEST.in`
- `cli/`, `main.py`, `examples/` (root)

## üß™ Testing Matrix

**Test Coverage by Feature:**
| Component | Unit | Integration | Critical Gaps |
|-----------|------|-------------|---------------|
| Agent Core | 78% | ‚úÖ | Error recovery |
| Function Calling | 70% | ‚úÖ | API failure handling |
| Observer Events | 75% | ‚úÖ | Console/file observers |
| Memory Management | 68% | ‚ùå | Cross-model memory |
| Tool System | 70% | ‚úÖ | Complex combinations |
| Multi-Agent | 65% | ‚úÖ | Method tools + multi-agent |

**LLM-Proof Testing Strategies:**
1. **External Knowledge**: `test_get_user_data_class_method` (data LLMs can't know)
2. **Complex Calculations**: Large number operations beyond LLM capability
3. **Explicit Instructions**: Force tool usage over LLM knowledge
4. **Tool Verification**: Assert tool calls, not just response content
5. **Optional Marking**: `@pytest.mark.optional` for flaky tests

**Model Coverage:**
- GPT-4o-mini: Native function calling + parallel tools
- Ollama/Phi: Text-based extraction + basic tools  
- Mock Models: All handler types in unit tests

## üìà Recent Improvements (2024-2025)

**Function Calling Cleanup Results:**
- 65% code reduction (Ollama: 401‚Üí137 lines)
- Native API usage (no pattern matching)
- 2025 features: parallel tools, streaming, fine-grained streaming
- 18/22 tests passing (core functionality intact)

**Repository Structure Cleanup Results:**
- 30% fewer root files
- Python packaging standards compliance
- Zero breaking changes for users
- Better IDE/tooling support

**Test Effectiveness Analysis:**
- 52 critical gaps identified across 10 test files
- Security testing prioritized (input validation, injection prevention)
- Cross-provider consistency validation needed
- Performance benchmarking required

## üîß Development Tools

**Located in `scripts/dev-tools/`:**
- `detect_tool_calling_format.py`: Analyze model responses
- `test_pattern_*.py`: Validate extraction logic
- `find_similarities.py`: Pattern analysis
- `batch_test_patterns.py`: Comprehensive testing

**Model Capabilities:**
- `model_capabilities.json`: Provider features, limits, API versions
- Dynamic detection via `detect_model_capability()`
- Cached results in `_MODEL_CAPABILITIES_CACHE`

## üöÄ Performance & Limits

**Provider Specifications:**
| Provider | Max Tools | Parallel | Streaming | Native Format |
|----------|-----------|----------|-----------|---------------|
| OpenAI | 128 | ‚úÖ | ‚úÖ | `tools` parameter |
| Anthropic | 64 | ‚úÖ | ‚úÖ Fine-grained | `input_schema` |  
| Groq | 128 | ‚úÖ | ‚úÖ | OpenAI-compatible |
| Ollama | 10 | ‚ùå | ‚úÖ | OpenAI-compatible |

**Expected Performance:**
- 30% latency reduction (no regex processing)
- 50% error rate reduction (native APIs)
- Better debugging (cleaner stack traces)

## üìã Critical Implementation Patterns

**Handler Selection:**
```python
# Direct mapping (no auto-detection)
tool_calling_type = get_tool_calling_type(model_name)  
handler = get_tool_calling_handler(tool_calling_type)
```

**Tool Registration:**
```python
@liteagent_tool
def my_tool(param: str) -> str:
    """Tool that LLMs can't perform without."""
    return external_api_call(param)

class MyTools:
    @liteagent_tool  
    def my_method(self, param: str) -> str:
        return self.process(param)
```

**Agent-as-Tool:**
```python
specialist = LiteAgent(model="claude-3-opus", tools=[domain_tools])
manager = LiteAgent(tools=[specialist.as_tool(name="expert")])
```

**Observer Usage:**
```python
observer = TreeTraceObserver()
agent = LiteAgent(observers=[observer])
observer.print_trace()  # Visualize interaction tree
```

## ‚ö†Ô∏è Critical Patterns & Anti-Patterns

**‚úÖ Do:**
- Use native provider APIs directly
- Test external knowledge, not LLM capabilities  
- Direct handler mapping (no runtime detection)
- Single responsibility per handler
- Standard Python project structure

**‚ùå Don't:**
- Pattern matching for native providers
- Test functionality LLMs can perform alone
- Auto-detection complexity
- Build artifacts in repo
- Hardcoded test values in production code

## üéØ Next Priority Actions

**Phase 1 Complete:** XPath removal, native handlers, repository cleanup
**Phase 2 Pending:** Security testing, error handling, cross-provider validation

**Immediate Focus:**
1. Implement critical security tests (input validation, injection prevention)
2. Add comprehensive error handling for API failures  
3. Test native function calling reliability
4. Validate cross-provider consistency
5. Performance benchmarking vs old implementation

**Success Metrics:**
- All handlers <150 lines ‚úÖ
- Native API usage only ‚úÖ  
- No pattern matching for native providers ‚úÖ
- Clean test separation ‚úÖ
- Zero breaking changes ‚úÖ

This consolidation represents 6 documents into 1 high-density reference covering architecture, implementation, testing, and development practices for LiteAgent.